# Автоматическая виртуализация рендеринга произвольной вёрстки

Здравствуйте, меня зовут дмитрий Карловский и я.. прибыл к вам из недалёкого будущего. Недалёкого, потому что там уже всё и все тормозят. Писец подкрался к нам незаметно: сначала перестали расти мощности компьютеров, потом пропускная способность сетей. А пользователи... они продолжали генерировать контент как не в себя. В итоге, за считанные годы UX интерфейсов деградировал настолько, что ими стало невозможно пользоваться и многие пользователи поспешили перейти на облачный стриминг своих браузеров, которые работают на суперкомпьютерах, принадлежащих корпорациям, которые не дают людям устанавливать на них блокировщики рекламы. Поэтому я пришёл к вам именно сейчас, в этот момент, когда проблема уже заметна, но ещё можно всё исправить, пока не стало слишком поздно. 

![](https://habrastorage.org/webt/c2/pv/0d/c2pv0do11or7p_ye3i5l_rp3fw4.png)

Это - текстовая расшифровка выступления на [HolyJS'20 Moscow](https://holyjs-moscow.ru/). Вы можете либо [посмотреть видео запись](https://youtu.be/RHOnH1DDLlQ), либо [открыть в интерфейсе проведения презентаций](https://nin-jin.github.io/slides/virt/), либо [читать как статью](https://github.com/nin-jin/slides/blob/master/virt/readme.md)...

# Тяжёлое прошлое: Огромные списки задач

Сперва расскажу немного о своём опыте. Мой релевантный опыт началася с разработки огромных списков задач, состоящих из нескольких десятков тысяч задач. Они образовывали иерархию и имели довольно причудливый дизайн, что осложняло применение virtal scroll. А таких списков задач на экране могло быть десятки разом. И всё это в реальном времени обновлялось, дрегендропилось и анимировалось.

![](https://i.imgur.com/4lYVPBX.png)

# Рекламная пауза: Богатый редактор

Так же я разрабатывал богатый, но компактный редактор текста, позволяющий множеству пользователей редактировать 200 страничные документы в реальном времени. У нас там применялся уникальный механизм синхронизации, минимизирующий конфликты, множество оригинальных UX решений и полностью кастомный виртуализированный рендеринг на холсте.

![](https://habrastorage.org/webt/t3/6n/qk/t36nqkbuxdix92ahd_ha9jprtw0.png)

К сожалению, он пал жертвой коронавируса, так что если кто-то захочет поднять знамя и продолжить его разработку, то пишите мне - я сведу с нужными людьми. Нужно будет выкупить права и доработать под свои нужы.

# Альтернативная линия времени: $mol

Ну и, конечно, нельзя не упомянуть про разработанный мною фреймворк, обеспечивающий автоматическую виртуализацию. Который задоминировал всех конкурентов.. В альтернативной линии времени. Там у нас все хорошо и поэтому я пришёл к вам.

[![https://mol.hyoo.ru/](https://mol.hyoo.ru/#app=components)](https://mol.hyoo.ru/#app=components)

Короче, съел я на теме виртуализации собаку, кошку, хорька, енота и даже морскую свинку. В общем, подкрепился как следует. Так что далее я расскажу вам как эффективно предоставлять пользователю огромные объёмы данных, почему вообще возникает такая необходимость, какие технологии нам с этим могут помочь, и почему Реакт ведёт нас в тупик.

# Типичный цикл разработки

Типичный цикл разработки выглядит так:

- Написали код.
- Проверили в типличных условиях.
- Пришли пользователи и всё заспамили.
- Оптимизировали.
- Пользователи всё не унимаются.

Мы уже взрослые ребята мы не пишем тяп-ляп и в продакшен. Теперь мы пишем код, проверяем его на тестовых данных, и если все хорошо, выкладываем в прод. Но тут приходят пользователи генерируют кучу контента и всё начинает тормозить. Тогда мы закатываем рукава и начинаем оптимизировать. Но приходят пользователи и генерят ещё больше контента и тормоза возвращаются вновь.

# Наивный рендеринг: Скорость загрузки и Отзывчивость

Этот порочный круг приводит к таким вот последствиям:

![](https://habrastorage.org/webt/x4/hn/3z/x4hn3zghvh8h83x60z4fegd9nj0.png)

Сейчас вы видите timeline загрузки и рендера двух с половиной тысяч комментариев. Скрипту требуется 50 секунд на формирование DOM, после чего еще 5 секунд нужно браузеру чтобы расчитать стили, лайаут и дерево слоев.

И это не картинка из будущего. Это самое натуральное настоящее. Замечу, что это хоть и мобильная версия, но открытая на ноуте. На мобилке все куда печальнее.

# Наивный рендеринг: Потребление памяти

Если мы заглянем на вкладку "память" то заметивм, что такая страница потребляет аж гигабайт.

![](https://habrastorage.org/webt/rp/bd/e9/rpbde9k6ewvsphe9x1umf8_ovh8.png)

На моем телефоне (потряхивает своим тапком) её меньше 3 гигов. И я думаю не надо объяснять откроется ли она у меня вообще. Тут мы плавно переходим к следующему риску..

# Наивный рендеринг: Риск неработоспособности

Если мы не влезаем по памяти, то приложение может закрыться. Причём может закрыть не одно, а утянуть с собой ещё несколько. А даже если не закроется, то чем больше приложение, тем дольше оно грузится. А чем дольше грузится, тем выше риск, что соединение оборвётся и всё придётся начинать заново. Ну либо довольствоваться первыми 4 комментариями из двух с половиной тысяч - реальная ситуация на моей мобилке.

- Не влезли по памяти - приложение закрывается.
- Обрыв соединения - страница обрывается.
- Браузер может заглючить на больших объёмах.

# Наивный рендеринг: Резюме

Короче, если мы продолжим разрабатывать наши интерфейсы том же духе, то неизбежно возникнут проблемы с медленной загрузкой, плохой отзывчивостью, засиранием памяти, а то и вообще падениями на ровном месте.

- Медленная загрузка.
- Плохая отзывчивость.
- Высокое потребление памяти.
- Риск неработоспособности.

# Первый подопытный: Статья на Хабре

Недавно я опубликовал статью, где рассказывал как можно ускорить [Хабр](https://habr.com) раз в десять, отказавшись от SSR.

[Вырезаем SSR и ускоряем Хабр в 10 раз](https://habhub.hyoo.ru/#author=nin-jin/repo=HabHub/article=34)

И там я собственно разобрал пример переписывания страницы дерева комментариев с применением виртуализации.

![https://nin-jin.github.io/habrcomment/#article=423889](https://nin-jin.github.io/habrcomment/#article=423889)

# Второй подопытный: Ченьжлог на GitLab

На сей раз мы разберём новый кейс - страница коммита на GitLab.

[![](https://i.imgur.com/zrawDWA.png)](https://gitlab.com/gitlab-org/gitlab-foss/-/commit/9517d0eb2ca8bde02d7fae2173e0a43b67b2b9f5#27e06e15cfe9583d733619cf7d72629b777f7757_26212_26221)

Я просто взял второй попавшийся коммит в первом попавшемся репозитории. Это всего порядка 5 тысяч строк в 100 файлах. Казалось бы - совсем не много. Однако, грузится всё доволно долго. Сначала 10 секунд ждём ответа сервера, потом ещё пол минуты любуемся мертвыми кусками кода без подсветки синтаксиса. Короче, приходится ждать почти минуту, прежде чем приложением становится возможно пользоваться.

# Перенос рендеринга HTML на сервер

Что ж, давайте откроем таймлайн и увидим там следующую картину.

![](https://i.imgur.com/Kq38m4l.png)

Пол минуты хтмл выдается браузеру. Обратите внимание что она вся фиолетовая. Это значит что каждый раз, когда браузер получает очередной чанк хтмл и подкрепляет его в документ, то пересчитывает стили, лейаут и дерево слоёв. А это весьма не быстрый процесс. И чем больше DOM, тем медленнее он становится.

Наконец, подключаются скрипты и сравнително быстро добавляют к коду подсветку синтаксиса. Но чтобы переварить такое массовое изменение огромного дерева, браузеру требуется потом ещё целых 3 секунды непрерывной работы.

# Страдания Ильи Климова по GitLab-у

Ну да ладно со скоростью загрузки. Один раз подождать ведь не проблема? Как бы не так! Браузер делает пересчёт стилей, лейаута и слоёв чуть ли не на кажды чих. И если вы попробуете поработать со страницей, то заметите, что на наведение указателя она реагирует весьма не рьяно, а вводить текст с лютыми задержками крайне не комфортно.

Год назад Илья Климов как раз рассказывал в свом выступлении страшные истории про работу как раз над этой страницей. Например, прикручивание спиннера заняло 3 месяца работы не самого дешёвого разработчика. А сворачивание небольшого файла вешало вкладку на 10 секунд. Но это, правда, уже оптимизировали - теперь на это требуется всего лишь пара секунд!

[![https://www.youtube.com/embed/3tdfBMRq34o](https://www.youtube.com/embed/3tdfBMRq34o)](https://www.youtube.com/embed/3tdfBMRq34o)

Причина этих ужастиков в том, что изначально была выбрана такая себе архитектура с такими себе технологиями, и писалось много типового кода пяткой левой ноги, а теперь вот нужно вкладывать кучу денег в Фонд Оплаты Труда, чтобы делать простейшие вещи долго и без существенного профита.

На мой вопрос "что ж вы на $mol всё это не перепишите, чтобы у вас всё летало?" Илья ответил, что не знает как его продать в компании. Что ж, надеюсь дальнейший разбор техник виртуализации поможет ему в этом нелёгком деле.

# Оптимизации вёрстки

Первое что приходит на ум - а давайте упростим вёрстку и DOM уменьшится. В качестве примера - кейс от Альфа-банка, который я разбирал в своей статье об истории $mol.

[$mol: 4 года спустя](https://habhub.hyoo.ru/#author=nin-jin/repo=HabHub/article=23)

Там был компонент вывода денежных сумм, который рендерился в 8 DOM элементов вместо 3.

```
<div class="amount">
    <h3 class="heading ...">
        <span>
            <span class="amount__major">1 233</span>
            <div class="amount__minor-container">
                <span class="amount__separator">,</span>
                <span class="amount__minor">43</span>
            </div>
            <span class="amount__currency"> ₽</span>
        </span>
    </h3>
</div>
```

```
<h3 class="amount">
    <span class="amount__major">1 233</span>
    <span class="amount__minor">,43 ₽</span>
</h3>
```

Не смотря на высокую частоту использования он был не оптимизирован. После моей статьи над ним поработали и теперь он рендерится в 5 элементов.

Если так поработать и над осталными компонентами, думаю можно уменьшить размер DOM раза в 2. Однако...

# Достоинства оптимизации вёрстки

Важно понимать, что асимптотика таким образом не меняется. Допустим страница грузилась 30 секунд. Вы оптимизировали, и она сала грузиться 10 секунд. Но пользователи сгенерируют в 3 раза больше контента и страница снова грузится 30 секунд. А оптимизировать вёрстку уже не куда.

- Кратное ускорение ✅
- Асимптотика не меняется ❌

Короче, годится эта техника лишь как временная мера, пока вы прикручиваете что-то по серьёзней.

# Прикладная оптимизация

Можно пошаманить над вашим прикладным кодом - кодом приложения, кодом ваших компонент. Тут есть несколько вариантов с разными ограничениями..

- Пагинация
- Экспандеры
- Бесконечный скролл
- Виртуальный скролл

# Прикладная оптимизация: Пагинация

Первое, что приходит на ум - это пагинация.

![](https://habrastorage.org/webt/e7/ps/nn/e7psnnp4ciudh1wb8egw-0zapxq.png)

Не буду рассказывать что это такое - все и так с ней прекрасно знакомы. Поэтому сразу к достоинствам...

# Достоинства пагинации

Во-первых пользователю приходится много кликать переключаясь между страницами - это тренирует его мелкую моторику. Кроме того приходится ждать загрузки ну или хотя бы рендеринга очередной страницы - есть время подумать о высоком: что он здесь делает, зачем и возможно решить что оно ему и не надо. Также постоянно теряется контекст, то есть тренируется память - ему нужно помнить что было там на предыдущей странице.

Быает, что элемент перескакивает между страницыми при переключении между ними. Это позволяет, например, ещё раз прочитать один и тот же комментарий, чтобы лучше его понять. Или наоборот, пропустить незамеченным - мало ли там какой-то негатив. А так он сохранит душевное равновесие.

Пагинация применима лишь для плоских списков, что избавляет пользователя от мудрёных древовидных интерфейсов.

Однако, если среди элементов на странице окажется какой-то особо крупный элемент, то опять вернутся тормоза. Но это будет всяко быстрее чем рендерить вообще все элементы на одной странице.

И, наконец, нельзя забывать про пользователей скринридеров, котрые будут вспоминать вас теплым словом каждый раз, когда им придется при переключении на очередную страницу снова стрелочками клавиатуры навигироваться от корня страницы до того контента который им интересен.

- Много кликать ❌
- Ожидание загрузки каждой страницы ❌
- Теряется контекст ❌
- Элементы скачут между страницами ❌
- Вероятность пропустить элемент ❌
- Применимо лишь для плоских списков ❌
- Большой элемент возвращает тормоза ❌
- Слепые вас ненавидят ❌
- Работает быстрее, чем всё скопом рендерить ✅

В общем, думаю вы уже поняли какое тёплое у меня отношение к пагинации. Я даже отдельную статью ей посвятил..

[Популярные антипаттерны: пагинация](https://habhub.hyoo.ru/#author=nin-jin/repo=HabHub/article=13)

# Прикладная оптимизация: Экспандеры

Можно выводить и на одной странице, но свернув каждый элемент под спойлером, а показывать его содержимое уже по клику.

[![https://nin-jin.github.io/my_gitlab/#collapse=true](https://nin-jin.github.io/my_gitlab/#collapse=true)](https://nin-jin.github.io/my_gitlab/#collapse=true)

# Достоинства экспандеров

Тут опять же приходится много кликать и ждать загрузки очередной ветки. Соответственно, мы тренирую мелкую моторику пользователя и позволяем ему подумать. Работает оно быстро, ведь нам нужно показать лишь список элементов, но не их содержимое. Но если пользователь откроет много экспандеров, то снова вернутся тормоза. Пользователи скринридеров будут вас жарко вспоминать за то, что им приходится еще и искать эти экспандеры и нажимать на них, что крайне неудобно когда пользуется клавиатура. и, наконец, самое главное преимущество: экспандер можно применять и для иерархических структур, а не только плоских списков.

- Очень много кликать ❌
- Ожидание загрузки каждой ветки ❌
- Если не закрывать, то снова тормоза ❌
- Слепые вас проклинают ❌
- Открывается быстро ✅
- Применимо не только для плоских списков ✅

# Прикладная оптимизация: Бесконечный скролл

Но что если мы не хотим тренировать мелкую моторику наших пользователей? Тогда можно применить, например, бесконечный скролл, так популярный в интерфейсах яндекса, например.

![](https://habrastorage.org/webt/7n/eq/s1/7neqs12fscopypxiafivw950key.png)

И сейчас вы видите скриншот яндекс диска. У меня есть там директория состоящая из пяти тысяч файлов. И если открытие её происходит относительно быстро, то, чтобы домотать до самого низа, требуется 3 с лишним минуты реального времени. Всё потому, что по мере скролла вниз, DOM становится всё больше и больше, от чего добавление очередного куска данных становится всё медленнее. В итоге, добавление последнего куска, например, занимает уже несколько секунд.

# Достоинства бесконечного скролла

- Применимо лишь для плоских списков ❌
- Ожидание загрузки каждой ветки ❌
- Увеличение тормозов по мере прокрутки ❌
- Быстрое появление ✅

# Прикладная оптимизация: Виртуальный скролл

Дальнейшее развитие бесконечного скролла - это виртуальный сролл, который не только дорендеривается снизу, но и удаляет контент сверху, по мере прокрутки вниз. И наоборот, при прокрутке вверх.

[![https://bvaughn.github.io/react-virtualized/#/components/WindowScroller](https://bvaughn.github.io/react-virtualized/#/components/WindowScroller)](https://bvaughn.github.io/react-virtualized/#/components/WindowScroller)

# Достоинства виртуального скролла

Тут размер DOM остаётся примерно постоянным, то есть интерфейс остаётся отзывчивым. Но годится это лишь для плоских списков. Для иерархических применять его зачастую больно - смотря какой визуал нарисовал дизайнер. Тут еще есть ещё такое ограничение, что нам должны быть известны примерные размеры элементов, чтобы мы могли рассчитать, какие элементы попадают в видимую область, а какие точно не попадают.

- Применимо лишь для плоских списков ❌
- Размеры элементов должны быть предсказуемы ❌
- Работает быстро ✅

# Прикладная оптимизация: Резюме

- Ухудшение пользовательского опыта ❌
- Не решают проблему полностью ❌
- Ограниченная применимость ❌
- Полный контроль где какую применять ✅

- Нужно не забыть ❌
- Нужно продавить ❌
- Нужно реализовать ❌
- Нужно оттестировать ❌
- Нужно поддерживать ❌

# Оптимизация инструментов

Чтобы не заниматься ручными оптимизациями каждый раз в каждом приложении можно пойти другим путем и оптимизировать инструментарий, то есть библиотеки, фреймворки, компиляторы и тому подобное. Тут есть опять же несколько подходов..

- Тайм слайсинг
- Прогрессивный рендеринг
- Ленивый рендеринг
- Виртуальный рендеринг

# Оптимизация инструментов: Тайм слайсинг

Можно попробовать так называемый time slicing. На одной из прошлых Holy JS я рассказывал про технику квантования вычислений, где долгое вычисление разбивается на кванты по 16 миллисекунд, и между этими квантами браузер может обрабатывать какие-то события делать плавную анимацию и так далее. То есть вы не блокируете поток на долгое время, получая хорошую отзывчивость..

[Квантовая механика вычислений в JS](https://github.com/nin-jin/slides/blob/master/fibers)

![](timeslice.png)

# Достоинства тайм слайсинга

Звучит вроде бы не плохо. Но тут есть такая проблема, как замедление общего времени работы всего вычисления. Например, если просто взять и выполнить вычисление без квантования занимает полсекунды, то если его постоянно прерывать каждые 16 мс, позволяя браузеру делать свои дела, то до завершения может пройти и пара секунд. Для пользователя это может выглядеть как замедление работы. Ну и другой аспект заключается в том что javascript не поддерживает файберы, то есть такие потоки исполнения, которые можно останавливать и возобновлять в любое время. Их приходится эмулировать тем или иным способом, а это всегда костыли, замедление работы и некоторые ограничения на то, как пишется код. В общем, с этим подходом всё не хочень хорошо, поэтому в $mol мы и отказались от квантования.

- Хорошая отзывчивость ✅
- Замедленность работы ❌
- Эмуляция файберов в JS ❌

# Оптимизация инструментов: Прогрессивный рендеринг

Частным случам time slicing является прогрессивный рендеринг, где DOM генерируется и подклеивается по кусочкам. Это позволяет очень быстро да ещё и анимированно показать первый экран и в фоне дорендерить страницу до конца. Такой подход реализован, например, во фромборке кэдбери..

[catberry.github.io](https://catberry.github.io/)

![](https://catberry.github.io/)

# Достоинства прогрессивного рендеринга

В $mol мы тоже [экспериментировали с подобным подходом](https://www.youtube.com/watch?v=hs9gv3TZgvA), но в итоге отказались, так как время появления даже первого экрана существенно замедлялось, а если страница была по настоящему большой, то всё вообще умирало, ибо по мере роста размеров DOM добавление даже маленького кусочка в него становилось всё медленнее и медленнее.

- Хорошая отзывчивость в процессе появления ✅
- Эмуляция файберов в JS ❌
- На больших объёмах всё встаёт колом ❌

# Оптимизация инструментов: Ленивый рендеринг

Вообще, изначально [в $mol у нас был так называемый ленивый рендер](https://www.youtube.com/watch?v=8pXBZH86MUs). Суть его в том, что мы сначала рендерим первый экран и помере прогкрутки добавляем столько контента снизу, чтобы видимая область была гарантированно накрыта. А при прокрутке вверх, наоборот, удаляем снизу тот контент, что гарантированно на экран не попадает, чтобы минимизировать размер DOM для лучшей отзывчивости.

[![https://nin-jin.github.io/my_gitlab/#lazy=true](https://nin-jin.github.io/my_gitlab/#lazy=true)](https://nin-jin.github.io/my_gitlab/#lazy=true)

# Достоинства ленивого рендеринга

Чтобы понимать сколько рендерить элементов, необходимо знать заранее минимальные размеры элементов, которые мы ещё не отрендерили. Но это решаемая проблема. А вот другая - не очень. Хоть появляется первая страница и быстро, но по мере прокрутки вниз увеличивается размер DOM, что неизбежно приводит к снижению отзывчивости. Так что если пользователь домотал до самого низа, то нам всё равно придётся отрендерить весь DOM целиком. То есть проблема отзывчивости решена не полностью.

- Размеры элементов должны быть предсказуемы ❌
- Увеличение тормозов по мере прокрутки ❌
- Быстрое появление ✅

# Оптимизация инструментов: Виртуальный рендеринг

Дальнейшее развитие ленивого рендера - это [при прокрутке не только добавлять контент снизу, но и удалять сверху. И наоборот при прокрутке вверх.](https://www.youtube.com/watch?v=ENc4G4dXL3g) В примере, вы можете заметить, что это работает не только с плоскими списками, но и с вёрсткой произвольной сложности.

[![https://nin-jin.github.io/my_gitlab/](https://nin-jin.github.io/my_gitlab/)](https://nin-jin.github.io/my_gitlab/)

# Достоинства виртуального рендеринга

- Размеры элементов должны быть предсказуемы ❌
- Работает, наконец, быстро ✅

# Оптимизация инструментов: Резюме

На уровне инструментов поддержка сейчас есть лишь в полутора фреймворках: time slicing в React, прогрессивный рендер в catberry и виртуальный рендер в $mol. Зато, такую оптимизацию инструмента достатоно реализовать один раз? и далее наслаждаться ею во всех своих приложениях не тратя дополнительное время на оптимизацию.

- Поддерживает полтора фреймворка ❌
- Работает само по себе ✅

# Оптимизации: Резюме

Так что именно на оптимизации инструментов я и предлагаю вам сконцентрировать свои усилия. И далее мы разберём, что нужно для добавления виртуализации на уровне фреймворка.

| Оптимизация    | Стоит того?
|----------------|---
| Вёрстка        | ❌
| Прикладной код | ❌
| Инструментарий | ✅

# Виртуализация браузера

Самое простое, что можно сделать, - это воспользоваться браузерной виртуализацией, которая появилась сравнительно недавно. Итак, открываем [гитлаб](https://gitlab.com/gitlab-org/gitlab-foss/-/commit/9517d0eb2ca8bde02d7fae2173e0a43b67b2b9f5#27e06e15cfe9583d733619cf7d72629b777f7757_26212_26221) и видим как всё лагает при движении мыши и вводе текста. Теперь произносим пару волшебных слов в девтулзах вокруг стилей "файла"..

```css
content-visibility: auto;
contain-intrinsic-size: 1000px;
```

И всё начинает летать. Устанавливая эти свойства, мы говорим браузеру, что он может пересчитывать layout только для видимой части, а для не видимой он будет брать ту оценку, что мы предоставили. Тут есть, конечно же, ограничение из-за которого иконка добавления нового комментария обрезается, но это решаемая проблема. А вот нерешаемая - это то, что нам всё-равно нужно потратить кучу времени на формирование огромного DOM. То есть таким образом мы можем обеспечить хорошую отзывчивость, но не быстрое открытие. Поэтому мы пойдем реализовывать виртуализацию именно на стороне яваскрипта.

# Логика рендеринга

Для каждого компонента нам нужно получить следующие данные.

![](render.png)

Во первых нужно пройтись по всем вложенным компонентом и узнать их оценку размеров. Так же нам нужно спросить у браузера как компонент расположен относительно вьюпорта. Использую эту информацию мы можем рассчитать какие элементы нашего контейнера попадают в видимую область, а какие не попадают. После чего добавить/удалить элементы в DOM.
И, на конец, обновить отступы, чтобы не полностью отрендеренный контент сместить в видимую область. И все эти операции повторяются рекурсивно для всех компонентов.

Далее мы пройдемся по этим шагам подробнее.

# Оценка размеров

Мы можем брать в качестве оценки, например, последний вычисленный размер. То есть при рендере запоминаем какой получился размер и далее используем эту информацию уже до рендера. Но тут такая проблема, что это не работает для тех элементов, которых мы еще рендерили. При плавном скроллинге - ничего страшного, но когда пользователь хватает скроллбар и тащит в другой конец страницы, нам не от куда взять инфомацию о размерах. Но самое страшное даже не это, а то, что нужно уметь вовремя инвалидировать кеш размеров, ведь они зависят от очень многих факторов, которые очень сложно все учесть.

Можно попробовать брать усредненное значение. То есть мы отрендерили, например, пять элементов из тысячи, вычислили среднее, и считаем что все остальные тоже в среднем такие же. Но это средняя температура по больнице получается, ибо в общем случае размеры элементов могут отличаться на несколько порядков. Среднее значение годится лишь в частном случае плоских виртуализированных списков, когда нам заранее извесно, что все элементы примерно одинакового размера. В общем же случае, для виртуализации на уровне фреймвока это совсем не подходит.

Так что самое оптимальное - это минимальная оценка. То есть сколько элемент точно занимает места. Он может быть больше, но точно не меньше. Это позволяет для заданной видимой области рассчитать сколько нам нужно отрендерить элементов, чтобы точно накопить суммарной высоты больше, чем размер видимой области. Отрендерим чуть больше - ничего страшного. Важно лишь, что  видимой области не будет дырок и пользователь не увидит, что мы немного сэкономили на рендеринге. 

- Последняя ❌
- Усреднённая ❌
- Минимальная ✅

# Типы компонент: Атомарный

Теперь о том как рассчитать размеры. Во первых мы можем просто напрямую задать эти размеры.

![](atomic.png)

Например, допустим все иконки у нас умеют размер 24х24, или любая строка текста имеет минимальную высоту в 24 пикселя.

# Типы компонент: Стек наложения

Если компонент составной, то нам скорее всего хочется, чтобы его оценка размера исходила из того, что мы поместили внутри него. Например, возьмем компонент "стек наложения" - этот компонент, который содержит другие компоненты, которые накладываются друг на друга, и его размер определяется максимальными габаритами среди всех вложенных в него элементов.

![](stack.png)

Соответственно мы просто берем максимальное значение минимального значения его элементов по соответствующим осям.

# Типы компонент: Вертикальный список

Для вертикального списка по горизонтали вычисляем так же, как для стека наложения. А вот минимальная высота списка равна сумме минимальных высот его элементов.

![](column.png)

# Типы компонент: Горизонтальный список

С горизонтальным списком всё аналогично, но возможно вам ещё потребуется учитывать смещение элементов относительно базовой линии, для вычисления минимальной высоты.

![](row.png)

# Типы компонент: Горизонтальный список с переносами

А вот с горизонтальным списком с переносами все несколько сложнее. Во первых нам нужно вычислить максимальную ширину нашего контейнера. Самая грубая оценка - это, например, ширина окна. Если у вас есть более точная оценка - замечательно. Но даже грубая оценка - лучше, чем ничего.

Далее мы берем все компоненты все вложенные компоненты и рассчитываем их суммарную ширину. Поделив одно значение на другое, мы получаем количество строк, которые точно будут
в нашем списке с переносами.

![](wrap.png)

В данном примере у нас будет два переноса, а следовательно после рендеринга он расползётся не менее чем три строки.

Далее, нам нужно рассчитать минимальную высоту строки. Это просто минимальное значение среди всех минимальных высот всех элементов. Так как мы не знаем места переносов, то более точно вычислить размеры строк не получится. Но нам важно, чтобы это значение было хотя бы не нулевым, чтобы виртуализация вообще работала. Умножая высоту строки на количество строк мы получаем минимально высоту всего компонента.

К сожалению, полную виртуализацию такого компонента сделать скорее невозможно, потому что не известно в каких местах произойдёт перенос. И если мы будем виртуализировать в обе стороны, то элементы будут скакать по горизонтали. Поэтому для таких компонент применим лишь ленивый рендеринг. То есть снизу добавляем и удаляем элементы, а свеху ничего не меняем.

# Типы компонент: Грид и Буклет

Такие компоненты, как гриды и буклеты, - это просто композиция упомянутых ранее.

![](grids.png)

Грид - они вертикальный список из горизонтальных списков. А буклет - это горизонтальный список из вертикальных списков.

# Типы компонент: Резюме

Итого, мы получаем 4 вида лейаутов, которые позволяют построить интерфейс любой сложности.

- Атомарный
- Стек наложения
- Вертикальный список
- Горизонтальный список

Но тут важно обратить внимание на то, что любой наш компонент должен быть одиного из этих четырех типов лейаута, иначе мы не сможем правильно оценивать размер. Эта информация должна быть задана в JS, а не определяться отдельно стилями.

# Отслеживание положения: onScroll

Теперь передем к вопросу о том, когда производить обновление DOM. Самое очевидное - это реагировать на событие `scroll`..

```
document.addEventListener( 'scroll', event => {
	// few times per frame
}, { capture: true } )
```

# Достоинства отслеживания onScroll

Тут есть 2 проблемы. Во первых, событие возникает слишком часто - его нет смысла обрабатывать чаще, чем 60 раз в секунду. Во вторых, размер и положение элемента относительно вьюпорта зависит от от многих вещей, а не только от позиции скроллбара. Учитывать все это в принципе можно, но очень легко что-то пропустить и не обновить DOM. В результате, пользователь может столкнуться с ситуацией, что он видит лишь половину страницы, но не имеет никакой возможности вызвать её дорендер даже вручную.

- Слишком часто ❌
- Изменения DOM ❌
- Изменения стилей ❌
- Изменения состояния элементов ❌
- Изменения состояния браузера ❌

# Отслеживание положения: IntersectionObserver

Может показаться что `IntersectionObserver` решит все наши проблемы, ведь он позволяет детектировать, когда пара элементов начинает или перестёт визуально пересекаться. Точнее, когда изменяется процент их пересечения. Если растянуть `body` на размер вьюпорта, то таким образом можно отслеживать процент пересечения любого элемента с видимой областью.

```
const observer = new IntersectionObserver(

    event => {
        // calls on change of visibility percentage
        // doesn't call when visibility percentage doesn't changed
    },
    
    { root: document.body  }
    
)

observer.observe( watched_element )
```

# Достоинства отслеживания IntersectionObserver

К сожалению, это не работает, когда у нас элемент выходит за границы видимой области и сверху, и снизу. При скролле, процент наложения таким образом может не меняться, а значит и событие вызваться не будет. А нам отслеживать такое перемещение все равно необходимо, чтобы понимать, что теперь нужно рендерить, например, элементы не с 5 по 10, а
с 10 по 15.

- Облом, если степень наложения не меняется ❌

# Отслеживание положения: requestAnimationFrame

Самый простой и надежный способ отслеживать габариты элементов - это опрос по requestAnimationFrame. Обработчик вызыватеся 60 раз в секунду и первое, чтто делает - подписывается себя на следующий фрейм.

Важно, чтобы оработчик вызывался самым первым, чтобы никто не успел до него внести изменения в DOM. Тогда размеры и координаты элементов будут браться максимально быстро - из кеша. Поэтому, следующим шагом мы пробегаемся по всем интересным нам элементам и получаем их габариты.

И только в самом конце производим изменения DOM. Если же читать размеры элементов после любого изменения в DOM, то браузеру придётся тут же произвести относительно медленный пересчёт layout. 

```
function tick() {

    requestAnimationFrame( tick )
    
    for( const element of watched_elements ) {
        element.getBoundingClientRect()
    }
 
    render()   
}
```

# Достоинства отслеживания requestAnimationFrame

Недостатком такого подхода является постоянная фоновая загрузка процессора. То есть мы тратим где-то одну-две миллисекунды на каждый фрейм. Это примерно 5% загрузка процессора на моём ноуте, что не очень много для интерфейса с которым в данный момент идёт работа. К счастью requestAnimationFrame не вызывается для фоновых вкладок, так что открытие произвольного числа вкладок не приведёт к неконтролируемому росту потребления ресурсов. Кажется это - разумная плата за простое и надёжное решение, накладывающее минимум ограничений.

- Постоянная фоновая нагрузка ❌
- Просто и надёжно ✅

# Обновление: Резюме

- onScroll ❌
- IntersectionObserver ❌
- requestAnimationFrame ✅

# Скачки при прокрутке

Если мы все это аккуратно реализуем, то у нас получится полностью виртуальный рендеринг произвольный верстки. Страница открывается мгновенно. Если матнуть в другой конец страницы - всё тоже показывается в гновение ока. 

[![https://nin-jin.github.io/my_gitlab/#anchoring=false](https://nin-jin.github.io/my_gitlab/#anchoring=false)](https://nin-jin.github.io/my_gitlab/#anchoring=false)

Но тут есть одна проблема. Если скроллить очень медленно, то легко заметить что контент немного скачет. Это происходит из-за несоответствия расчётной высоты элемента и фактической. И чем больше эта разница, тем сильнее будут скачки. Вплоть до невозможности пользоваться скроллом.

# Привязка скролла: Предотвращает скачки

Есть классический пример демонстрирующий проблему..

![codepen](https://codepen.io/chriscoyier/embed/oWgENp?theme-id=dark&default-tab=result)

Справа у нас есть некоторый контент. После того как мы проскроллим, сверху добавляется куча дополнительных боков. Эти блоки смещают контент вниз, из-за чего он улетается из видимой области. Вроде бы логично, но нифига не удобно для пользователя.

Слева же применяется новая браузерная фича, которая привязывает скроллбар к видимой области. И после добавления блоков сверху, браузер автоматически смещает скроллбар вниз, чтобы видимый контент остался на месте.

# Привязка скролла: Выбор точки привязки

Чтобы выбрать элемент для привязки скролла, браузер идёт по DOM от корня в поисках первого же элемента, попадающего в видимую область. Заходит в него и снова ищет первый попавшийся. И так далее. При этом совершенно не важно как элементы друг относительно друга расположены визуально. Важно лишь расположение их в доме и попадают ли они в видимую область. Разберём этот процесс на простой мримере..

![](anchor.png)

Элемент `1` не видим, поэтому пропускаем. `2` видим, так что заходим в него. Тут и `2.2`, и `2.3` видимы, поэтому заходим в первый. Далее ближайший видимый `2.2.2`, внутри которых видимых больше нет, так что именно этот элемент становится якорем для привязки скролла. Браузер запоминает смещение верхней границы якорного элемента относително вьюпорта и старается его сохранить постоянным.

# Привязка скролла: Подавление привязки

Тут есть один нюанс - якорным элементом может быть только такой, для которого и для всех предков которого не запрещена привязка скролла. То есть элементы с запрещённой привязкой просто перескакиваются в поиске якорного эелмента. А запрещена она может быть либо явно, через свойство `overflow-anchor`, либо неявно, при изменении css свойств влияющих на размеры и положение элемента.

- `overflow-anchor: none`
- `top`, `left`, `right`, `bottom`
- `margin`, `padding`
- Any `width` or `height`-related properties
- `transform`

# Виртуализация: Распорки

Так как мы рендерим не весь контент, а только часть, нам нужно как-то сместить его так, чтобы он оказася в видимой области. Но мы не можем сделать это напрямую, иначе для его будет запрещена привязка скролла, которая нам нужна, чтобы не было видимых скачков. Поэтому, вместо пропущенных элементов мы вставляем распорку и задаём ей высоту. Таким образом распорка смещает контент в нужную нам позицию, а браузер не подавляет привязку скролла.

![](gaps.png)

# Виртуализация: Прокрутка вниз

Рассмотрим несколько сценариев работы виртуализации с привязкой скролла. Для примера, возьмем компонент вертикального списка. Изначально видны элементы 3, 4 и 5, а сверху и снизу - распорки.

![](overlap-top.png)

Зелёная фаза - пользователь скроллит вниз. Как видно третий блок вышел из видимой области, а снизу образовалась дырка. Но пользователь это ещ1 не видит.

Синяя фаза - срабатывает обработчик requestAnimationFrame и мы обновляем DOM: удаляем третий узел и добавляем шестой. Как видно, контент уехал вверх относительно видимой области, но пользовател это ещё не видит.

Красная фаза - мы отдаём управление браузеру, а тот выбирает 4 элемент в качестве якоря и отскролливает чуть-назад. Так что пользователь видит лишь добавившийся снизу шестой элемент.

# Виртуализация: Прокрутка вверх

Аналогичная ситуация и со скроллингом вверх. Разве что в качестве якоря выбирается четвёртый элемент, а не третий, так как третий изменил положение в DOM, то есть появился в данном случае.

![](overlap-bottom.png)

# Виртуализация: Расширение

Может так оказаться, что контент не достигает краёв видимой области с обоих концов. 

![](inside.png)

Мы просто добавляем контент и браузер снова смещает скролл так, чтобы контент, что был изначально виден, остался на месте.

# Виртуализация: Превышение

Возможна и обратная ситуация: контент уже полностью накрывает видимую область с запасом. Можно было бы удалить невидимые элементы, но лучше не трогать DOM лишний раз. Пусть лучше пользователь мотает скроллом туда-сюда без зареджек на обновление DOM пока не появится дырка с одной из сторон - тогда имеет смысл удалить лишнее с противоположной стороны. И как следствие DOM не будет неограниченно разрастаться.

![](nothing.png)

# Виртуализация: Скачок кенгуру

Нельзя не упомянуть особый случай, когда пользователь хватает за скроллбар тащит в другой конец документа. Если никак дополнительно не обрабатывать этот кейс, то придётся отрендерить много элементов, чтобы накрыть видимую область. При этом больше их часть будет невидима, а значит много работы проделана зря. А лишняя работа - это лишние задержки, порой недопустимо большие.

![](after.png)

Чтобы такого не происходило нужно просекать, что все элементы вышли из видимой области, удалять их все полностью и начинать рендеринг с нуля, отталкиваясь от текущего смещения скролла. Нам нужно пропустить столько элементов, чтобы размер распорки оказался чуть меньше расстояния до верхней границы видимой области. Таким образом первый элемент гарантированно накроет верхнюю её границу. И остаётся лишь дорендерить столько элементов, чтобы накрыть ещё и нижнюю границу. 

# Привязка скролла в действии

Если всю эту логику мы реализуем аккуратно, тогда не будет никаких скачков, даже несмотря на то, что какие-то элементы окажутся не той высоты, что мы рассчитывали.

[![https://nin-jin.github.io/my_gitlab/](https://nin-jin.github.io/my_gitlab/)](https://nin-jin.github.io/my_gitlab/)

# Привязка скролла: Поддержка

Однако, есть проблема с интернет эксплорером нашего времени, который всё ещё не поддерживает привязку с скролла.

| Браузер | overflow-anchor
|---------|---
| Chrome  | ✅
| Firefox | ✅
| Safari  | ❌

# Привязка скролла: Запасный выход

Для отсталых браузеров необходимо детектировать поддержку привязки скролла и, если её нет, то фолбечиться до ленивого рендера, то есть менять DOM лишь ниже видимой области, но не выше.

```
const anchoring_support = CSS.supports( 'overflow-anchor:auto' )


if( anchoring_support ) {
    virtual render
} else {
    lazy render
}
```

# Проблема: Долгая раскладка

Если в следующем примере выключить пару CSS оптимизаций, то можно заметить, что скроллинг как-то подлагивает. Далее мы разберём суть этих оптимизаций.

[![https://nin-jin.github.io/habrcomment/#article=423889](https://nin-jin.github.io/habrcomment/#article=423889)](https://nin-jin.github.io/habrcomment/#article=423889)

# Минимизация расчётов лейаута

Так как мы всё время меняем DOM внутри скроллящейся области, то это приводит к тому, что баузеру приходится постоянно пересчитывать лейаут, стили и дерево слоёв всего документа. Поэтому для скроллящихся областей имеет смысл задать следующее CSS свойство..

```
[mol_scroll] {
    contain: content;
}
```

Оно говорит браузеру, что содержимое скроллящейся области не влияет на раскладку и стили вне её. Это позволяет существенно уменьшить стоимость браузерных пересчётов.

# Прокрутка в отдельном потоке

Другая проблема заключается в том, что рендеринг скроллящейся области может происходить синхронно, в основном потоке, где работают наши скрипты. А это значит, что пока мы не закончим все наши вычисления, браузер не может плавно анимировать прокрутку. Чтобы это побороть, нужно заставить браузер вынести содержимое скроллящейся области в отдельный слой. Сделать это проще всего следующим хаком..

```
[mol_scroll] > * {
    transform: translateZ(0);
}
```

На глаз отличить синхронный скролл от асинхронного не сложно: синхронный подлагивает, но никогда не показывает дырок, а вот асинхронный плавный, но может показывать дырки, когда мы не успеваем дорендеривать контент.

# Плавная прокрутка (или нет)

Применив все оптимизации мы получаем плавную прокрутку..

[![https://nin-jin.github.io/habrcomment/#article=423889](https://nin-jin.github.io/habrcomment/#article=423889)](https://nin-jin.github.io/habrcomment/#article=423889)

..пока используем палец или автопрокрутку. Но стоит нам взяться за колёсико или тачпад, то оказывается, что привязка скролла порой не работает. Оказывается, что если открыть приложение во фрейме другого приложения, которое расположено на другом домене, то привязка скролла в Хроме пересаёт работать. Если для вас этот кейс имеет значение, то стоит его детектировать и фолбечиться до ленивого рендера.

# Логика поиска

```
*find_path(
	check: ( view : View )=> boolean,
	path = [] as View[],
): Generator< View[] > {

	path = [ ... path, this ]
	
	if( check( view ) ) return yield path

	for( const item of this.kids ) {
		yield* item.find_path( check, path )
	}

}
```

- Рекурсивно спускаемся по компонентам.
- Отбираем соответствующие запросу.
- Рисуем интерфейс перехода между найденным.

# Логика прокрутки к компоненту

```
scroll_to_view( view: View ) {

	const path = this.find_path( v => v === view ).next().value

	this.force_render( new Set( path ) )

	view.dom_node.scrollIntoView()

}
```

# Логика форсирование рендеринга видимого

```
force_render( path : Set< View > ): number {

	const items = this.rows
	
	const index = items.findIndex( item => path.has( item ) )

	if( index >= 0 ) {
		this.visible_range = [ index, index + 1 ]
		items[ index ].force_render( path )
	}

	return index
}
```

# Работающий поиск

[![https://nin-jin.github.io/habrcomment/#article=423889](https://nin-jin.github.io/habrcomment/#article=423889)](https://nin-jin.github.io/habrcomment/#article=423889)

# Доступность

[![https://nin-jin.github.io/my_gitlab/](https://nin-jin.github.io/my_gitlab/)](https://nin-jin.github.io/my_gitlab/)

# Решаемые проблемы виртуализации

- Оценка будущих размеров.
- Скачки контента.
- Тормоза при скроллинге.
- Прокрутка к элементу.
- Поиск по странице.
- Доступность.

# Фундаментальные особенности

- Скачки скроллбара при неточной оценке размеров.
- Scroll Anchoring может не работать в некоторых контекстах.
- Копирование выделенного текста.

# Бенчмарки: Скорость открытия и Отзывчивость

![](https://habrastorage.org/webt/qf/h7/g9/qfh7g9fze_nlbveaxf9t2dfwh7i.png)

Сверху статья на Хабре. Мобильная версия. Меньше 200 комментариев без самой статьи рендерятся на VueJS. Снизу примерно то же самое на $mol. Отображается и статья, и комментарии.

# Бенчмарки: Отзывчивость

Остальные бенчмарки: [dbmon](https://mathieuancelin.github.io/js-repaint-perfs/).

[![https://mol.js.org/perf/dbmon/-/](https://mol.js.org/perf/dbmon/-/)](https://mol.js.org/perf/dbmon/-/)

# Бенчмарки: Потребление памяти

| Вариант                           | Память JS                                             | Память вкладки
|-----------------------------------|-------------------------------------------------------|-------------------
| [VueJS: **170** комментариев](https://m.habr.com/post/522578)                                 |40 MB     | 150 MB
| [$mol: **статья + 2500** комментариев](https://nin-jin.github.io/habrcomment/#article=423889) | 40 MB     | 90 MB

# Бенчмарки: Гулять так гулять!

[![https://showcase.hyoo.ru/](https://showcase.hyoo.ru/)](https://showcase.hyoo.ru/)

# ООП против ФП

- **Объект**: одно состояние - много действий.
- **Функция**: много состояний - одно действие.

# Ортогональные действия

- Узнать минимальные размеры.
- Частично отрендерить содержимое.
- Проверить соответствие поисковому запросу.

# Композиция против вёрстки

```tree
Column
	Row
		Search
		Icon
	Scroll
		Column
			Task
			Task
			Task
```

```html
<main class="panel">
	<div class="header">
		<input class="search" />
		<img src="..." class="icon" />
	</div>
	<div class="scroll">
		<div class="card" />
		<div class="card" />
		<div class="card" />
	</div>
</main>
```

# Перспективы во фреймворках

| Инструмент | ООП | КОП
|------------|-----|----
| React | ❌ | ❌
| React Native | ❌ | ✅
| Vue | ✅ | ❌
| Angular | ✅ | ❌
| Svelte | ✅ | ❌
| $mol | ✅ | ✅

# Выбери виртуализацию

![](https://i.imgur.com/Y2qj6cr.png)

# Ссылочки

- [nin-jin/slides/virt](https://github.com/nin-jin/slides/tree/master/virt) - эти слайды.
- [nin-jin/slides](https://github.com/nin-jin/slides) - другие мои выступления.
- [habhub.hyoo.ru](https://habhub.hyoo.ru/) - мои статьи.
- [`_jin_nin_`](https://twitter.com/_jin_nin_) - моё ворчание.

- [nin-jin/my_gitlab](http://nin-jin.github.io/my_gitlab) - ченьжлог на $mol.
- [nin-jin/habrcomment](http://nin-jin.github.io/habrcomment) - хабрастатья на $mol.
- [mol_news](https://t.me/mol_news) - $mol новости.

# Обратная связь

![](https://habrastorage.org/webt/-c/vu/6i/-cvu6iyueghl7bh37sld_nstysw.jpeg)

## Превосходно: 34%

- Вроде все знакомо, но нашел для себя пару интересных нюансов.
- Узнал кое что новое.
- Все ок.
- По моему мощнейший доклад, очень круто и интересно. Один момент. У Дмитрия сквозь доклад использовалась шутка: недостатки преподносились как преимущества (в духе контент прыгает - пользователь тренируется концентрировать внимание). Она удачная и смешная (правда так считаю, не из вежливости это пишу), но ее было слишком много. Например, был слайд, где было сразу много "преимуществ", и Дмитрий проговаривал по шутке на каждый пункт. Ломало темп. Сначала весело, а потом уже как-то хочется чтобы доклад дальше двигался. Но это минорное замечание, доклад 🔥
- Изначально я слышал про $mol из комментариев на хабре, многие из которых были неуместны / подавались в странной манере. В докладе я увидел, что автор - "видел некоторое дерьмо" (простите за мем) - понимает причины - предлагает здравые рассуждения по тому, как это чинить. Совершенно точно посмотрю на эту библиотеку, чтобы увидеть воплощение принципов из доклада на практике. Но даже если не буду использовать эту библиотеку в проде, разочарован не буду - настолько ценной и качественной я считаю информацию в этом докладе.
- Подача, глубина доклада, практическая применимость, простота восприятия, новизна.
- На удивление было мало $mol и много полезных вещей)

## Хорошо: 42%

- Интересный доклад, но к сожалению не все было понятно, начиналось вроде все просто, но потом быстро вышло за мое понимание).
- Карловский как всегда жжет.
- Очень круто и глубоко, но не очень понравилась подача. Хочется побольше "огонька".

## Нормально: 18%

- Слишком узкая специализация
- Что смотрел помню, а про что нет.
- Доклад на мой взгляд получился последовательным, но не очень сбалансированным с точки зрения теории и практики. Тема доклада очень общая, а по итогу практическую пользу можно получить судя по всему, если использовать конкретный фреймворк. Из плюсов - понравился разбор проблемы на примере GitLab.

## Плохо: 6%

- Интересный материал, интересная тема, большой потенциал технологии. Не понравился спикер и его отношения к другим технологиям, людям.
- Оценка поставлена из-за несоответствия моих ожиданий и реальности =)Ожидания: я смогу применить полученные знания на своем проекте.Реальность: демонстрация своего фреймворка. Для проектов на любом другом фреймворке полученная информация неприменима. Если бы это было понятно из названия и описания, я бы не тратила время и пошла на другой доклад.

# Расшифровка

вот если вот эту логику мы реализуем все
правильно
тогда у нас не будет никаких скачков
сейчас видите никаких скачок не
наблюдается даже несмотря на то что
какие-то строки у нас
рендерилось
не той высоты что мы рассчитываем
например вот эта строка она перенеслась
поэтому она не 24 пикселей
оказалось 48
ладно
своим
я случайно пришел по сути так но тут
есть проблема с интернет эксплорер у
нашего времени при не поддерживает
привязку с пола
чтобы это побороть необходимо
детектировать что есть поддержка или нет
если ее нет пол бычить
рендеринг да собственно ленивый
выключать изменения контента сверху
отопить области
вот но тут есть еще такая проблема
сейчас я выключу несколько оптимизации
чтобы показать
ее суть
так
душ
и вот так мы выключили несколько
оптимизации и теперь можем увидеть
проблему
вот я сейчас крови и можете заметить ну
или не заметить что скроется но не
всегда 60fps сами иногда фпс проседает и
видно какие затыки скроллинге происходит
это потому что браузера в данном случае
производит рендеринг синхронно то есть
если мы сейчас быстро про скролим то мы
не увидим снизу белой области
который мы бы наблюдали если бы браузер
оптимизировал скроллинг чтобы
[музыка]
все работало быстро нам нужно следующий
оптимизация во первых для самого
сокровище области необходимо добавить
контент контент который скажет браузера
что все что мы там кроме меня внутри
сколь ищите области а мы это дело
постоянно
она не влияет на стиль и layout всего
что находится в несколько чисел
то есть браузер не нужно пересчитывать я
вот вообще всей страницы кроме того что
более важно необходимо добавить как
который форсирует вы нас всего контента
скроле щийся области в отдельный слой
только тогда browsers может
активизировать это дело и делать
анимацию скролла в отдельном трейдинг
то есть мы в основном трети можем
сколько угодно генерировать обновлять
дом
но это не будет влиять на плавность
анимации сколько она будет водяным треде
предсказать вот и с этими оптимизация my
соответственно у нас все будет 1 до
плане
так
android
портмоне из за того что у меня не
успевает дар нравится появляется белая
область низу вот и плавно но все
работает ровно до тех пор пока мы
используем палец для того чтобы
коллировать или авто прокрутку через
лень и club лучше но если мы используем
[музыка]
тачпад или колечко мыши то мы получаем
снова какие очки землю у нас все куда-то
я когда готовил это выступление это
выяснил внезапно
оказалось если у вас приложение
открывается в храме в другом приложении
эти приложения находятся на разных
доменах но почему то вот рассказ крыло
открыться для кого-то это может быть не
критично но если вам это критично то
нужно просто добавить фон back
доля него рендеринга так
еще одна проблема которая у нас осталась
нерешенной а это поиск пример мы хотим
поискать страницы
ой
ничего не нашли потому что у нас от
рендере на только маленькая часть
страницы
давайте попробуем реализовать
собственную логику поиском для этого нам
нужно пройтись по всему дереву
рекурсивно пройтись по дереву компонент
и поспрашивать у компоненты
соответствуешь ты
поиск или не соответствуешь и собрать
все пути до всех таких элементов после
чего можно построить
интерфейс где там будет вывод количество
найденных элементов кнопочки
вперед-назад и так далее по клике на
кнопочки вперед назад хорошо бы
фокусировать пользователь на том
элементе на котором
ну на следующем на 10 иметь и но
поскольку он еще не на неё тренды в дом
то мы не можем просто выполнить для
этого нам нужно сначала форсировать
рендеринг всех элементов по пути до
нужного нам его родители родителей когда
и только по столу когда он фактически
окажется в доме в нужном месте когда уже
делать с крылом тулью то есть
браузер будет про скромен и у нас от
работает логика виртуализации будут
добавлены элементы сверху снизу
ну и наконец
логика форсирования рендеринга она
достаточно простая в данном случае метод
вертикального списка он среди своих
элементов ищет тот элемент который
находится в пути которые мы хотим
форсировать рендеринг и он перемещается
одно окно рендеринга таким образом чтобы
в него попадал нужны нам элемент и
производит эту операцию рекурсивно чтобы
времен тоже внутри себя все эндрю вот
если мы все это реализуем аккуратно
тогда у нас будет работать поиск
так
винт вот видите мы нашли четыре варианта
не можем переключаться между найденный
вариант
замечательно но есть проблема с
доступностью
я показывать не буду но в общем суть в
том что
читалки они
чтоб
читалки они
читают текст последовательно по строчкам
то есть каждый раз когда они читают
очередной строку они фокусируют
[музыка]
фокусируют браузер на этой строке если
мы читаем сейчас последнюю строку а
следующая строка находится за пределами
видимой области
то ну мы как бы ее не от рендер ли
потому что она невидима и читалка скажет
что типа все конец приехали чтобы такого
не происходило рендерить надо чуть чуть
больше следующая строка тоже от
рендерилось
и таким образом когда читалка перейдёт к
следующей строки она сфокусирует браузер
чуть-чуть от скроллер и
у нас работает виртуализации добавится
еще строить таким образом даже через
screen breeder все это будет достаточно
доступно youtube и какие проблемы мы
решили
мы научились оценивать размеры любых
компонентов мы побороли скачки контента
тормоза при скроллинге научились и
искать по виртуализированные странице
откручивать нужному нам элементу и
обеспечили хорошая доступность удобства
людей
пользующихся screen ридерами тем не
менее у нас остались некоторые
фундаментальные особенности такие как
скорость скачки scrollbar из-за того что
наш расчетный размер не совпадает с тем
как он будет фактически это будет
немного скакать это свойство вообще
любых детализированных интересов
кроме того привязка скролла может не
работать некоторых текстах это нужно
быть готовым и особенно внимательным
кроме того есть проблема с копированием
и выделением текста поскольку в доме его
не тот он нужно все это как-то хандрить
вручную это тема отдельного исследования
потом я пока еще не знаю ну ладно
давайте погоняем бенчмаркинг
возьмём какую страницу хабра на а также
мобильного открываем комментарии
допустим комментариев у нас 170 х брюс
для этого требуется три с половиной
секунды чтобы преодолеть дом и еще пол
секунды чтобы браузеру моя реализация на
море
требует 0 3 секунды чтобы обработать
статью а потом браузеру нужно 0 2
секунды чтобы показать то что мы от
рендер или видим области и потом
подгружаются комментарии
еще требуется 0 3 секунды чтобы
обработать комментарии ну там
сформировать дерево компонент вычислить
минимальные размеры все такое прочее и
как видите браузер и вообще ничего не
потребовалось для
визуализации потому что мы в доме не
фактически они поменяли комментарии
попадают видим область мы просто
изменили размер раскопки то есть мы
потратили меньше секунды для того чтобы
показать страницу которая сейчас охапкой
рендерится 4 секунд
можем погонять всякие бенчмарки
синтетические напряги монитор
вот сейчас он показывает и нас vps но
когда у меня система не так загружено он
показывает стабильность все остальные
который rendered все они показывают
гораздо меньше там 30 40
если посмотреть по памяти то реализация
хабаровска которая навеют же с рендере
170 комментариях отжирает 40 мегабайт
памяти но если посмотреть понять вкладке
то это в 3 раза больше на самом потому
что браузеру нужно весь этот дом и
обрабатывать
если же мы откроем реализацию на море
где которая показывает искать у еще без
плане тысяч комментах кто получил что
памяти мы забираем столько же
опали вкладке еще меньше то есть поли
зация она дает весьма такой честный
погиб мы можем оказывать на порядок
большой информации тратя кратно меньше
ресурсов
это и это не значит что но какой то
супер быстрый компактный все такое
прочее
если во вью какой-нибудь в 5 версии
прикрутят
виртуализация он тоже сможет показывать
такие крутые результаты ну и тут я хотел
вам показать как все быстро грузится
новой системы сейчас один работает что
боюсь
впечатление будет крутое но когда у меня
система не загружена эта страница
грузится за 6 секунд
тут сейчас открывается 25 реальных
морских приложениях если сравнивать с
вариантом гид лобо который грузится
полминуты это всего одно положение
то есть небо и земля король
актуализации то вообще классная тема и
давайте посмотрим какие у нас есть
перспективы того что оно появится в
текущих инструментов
но сперва определимся с вопросом
чем объект отличается от функции объект
это одно состояние и много действий
которые можно с ним совершить то есть
методы а функция это некоторое одно
действие но она может работать с разным
состоянием какой быть angular использует
концепцию объектов
каждый компонент объект а в реакция
популярна тема функциональный компонент
и компонент имеет дело только одно
действие тип тренда это все свое
содержимое однако при виртуализации нам
необходимо иметь разные действий во
первых
мы должны уметь спрашивать у компонента
какие у тебя минимальные размеры причем
сделать это нужно как можно быстрее не
делая полный рендеринг со всеми деталями
всего содержимого во вторых нам нужно
возможность от рендерить только часть
содержимого компонента вкуснее все
десять тысяч адамс 5 50 и наконец
нам нужна дополнительная ручка что
проверить соответствует
компонент поисковому запросу ганизации
ведь нам нужно много действий и на
функциональный подход это ложится
большим трудом кроме того стоит
упомянуть
различные подходы к композиции то есть
это может быть либо композиций компонент
как слева то есть мы собираем прошу
положение и за
каких-то компонент и нам и рендерер
может спросить колонка какие у тебя
минимальные размеры она знает про
кончится
числе своим внимания разгар но более
популярный подход с оживлением готовые
верстки
нас есть какие-то html5 какие-то классы
там но render.ru вообще не понятно что
себя все
не проанализировать ссс теоретически
можно написать свой
тесс везло который все это вычислить но
это будет большой объем кода это будет
медленно работать и в конечном счете это
будет не очень надежно потому что если
мы накосячим 1 организация становится
другой если сравнить
разные существующие инструменты то можно
заметить что моряк например идет вообще
куда-то совсем не в ту сторону и к нему
прикрутить можно ли
и скорее всего не будет никто и отметив
чуть чуть ближе потому что там нет
никакого сырого хтмл с я счас а вы все
строить из компонент там будет опять же
нужно будет прикручивать чтобы была
возможность выполнять с компонентом
разные действия в angular съел то там
каждый компонент это объект но они
заточены на то что они оживляют уже
существующую doors произвольно
но в молле виртуализация уже давно
работает так что домов опять всех
победил
но я не предлагаю вам
использовать мол потому что знаете
использовать потребительское стране
я вам предлагаю присоединиться к
разработке мола и тем самым получить
максимальный профит
либо вы можете разработать свой какой-то
инструмент
основанный на виртуализации любом случае
какой бы вариант вы не выбрали
обращайтесь ко мне и я помогу чат ну и
наконец ссылочки ссылка на эти слайды
другие мои выступления их там или больше
можно почитать мои статьи мое ворчание в
твиттере и наконец 2 дымке очень блок
div лобов ский молли и
хабра комментарии и в конце собственно
можете подписаться на новости мола у нас
наполеоновские планы
на этом пока что все и я готов к обратно
большое спасибо за доклад дмитрий было
интересно послушать его даже не первый
раз все равно открывать что-то новое
более чем у нас есть вопрос от
слушателей и предлагаю наверное
начать вопрос от слушателей артем пишет
половину проблем связана с расчетами для
правильного отображения scrolls
scrollbar от его размера позиции так
может поменять сам scrollbar
например заменить ползунок качелькой
которую там чем сильнее тянешь тем она
там больше скроллер и
и наоборот то есть что-то похожее на
работу трекбола например сделать
что ты думаешь по этому поводу
да и такое пытались сделать
google и ну прям в пика сито 5 и это
было очень неудобно на самом деле потому
что тебе приходится регулировать не
координату а скорость изменения
координаты это пользователю сайт гораздо
сложнее делать
вот и не проходит кровь парк может
показывает конкретное положение на
странице то есть не по нельзя понять
мы вначале там в конце
и широко плеча
когда
вопросах где та грань и в который может
вмешиваться в фреймворк где мы должны
использовать стандартный браузер на япе
а что из этого можем менять то есть
условно
вас коробка вся говоришь лучше не
вмешиваться но мы вмешиваемся в
композицию листов до длинных
как ты думаешь ждет проходит вот эта
незримая грань за который лучше не
заступать тут единственный критерий
практичность то есть если это дает
больше профита чем ограничение так
studios
понятно хорошо следующий вопрос у меня
тут их много есть смотри я по поводу
расчета размеров позиции ты не
экспериментировал со screen канваса мож
немножко рассказать вот что он нам могут
дать в условный в worker еда что в них
сейчас не хватает
что уже сейчас может туда перенести для
расчета размеров элементов да я
разумеется использовал холст для
рендеринга собственных документы ан-30
именно через холст
чтобы добиться pixel perfect как раз и
тут как раз виртуализация просто
необходимо потому что вам уже никто не
помогает вам нужно в картинку
отрендерится только текущие видимое
пользователю если вы будете все 200
страниц документа рендерится это будет
крайне медленно вот скрин канва сам я не
работал потому что когда реализовывал
спинка носа поддержки еще не
вот но выглядит перспективно самом деле
что мы можем какое-то вычисление делать
в отдельном потоке с другой стороны
пользователь взаимодействует с
вашей конвой в основном потоке поэтому
то что вы отрыв будете долго рендерить в
отдельном потоке это все равно не даст
вам хороший отзывчивости
понял тебя смотрели ещё один вопрос по
поводу мола и того как он рендерит
именно списке перри используется ли дом
моды компонентов списка или при скроле
постоянно создаются новые элементы
я эксплуатировался be my вариантами в
итоге пришел к тому что
создать новый элемент не так уж и дорого
вот а вот бороться с тем что у старого
элемента осталось старое состоянии с
этим могут быть проблемы
очистить
она сама распространен например которое
видел это если мы видим равен dream
список аватарок и у нас из-за того что и
мышь этой синхронный так он может
отображать что старое значение когда мы
уже раскрыли играет очень неприятный
смотри такой вопрос по поводу
производительности не пробовали ты
рендерит списке и именно вы фрейм этом
текущего домена
например чтобы попытаться рангу пидары
синхронизировать и логику рендеринга или
проще всего это именно через css решать
или просто не могу смотреть фреймы это
такая довольно тяжеловесная штука то
есть фактически
целый вкладку открываете себя внутри
другой вкладке и сама добавление фреймы
это очень долго то есть у меня там есть
где-то benchmark где добавляются
различные элементы
и там девочек добавить за считанные
миллисекунды добавление фреймов это прям
все стоят колом и
да и кроме того фрейма кушаю куча памяти
очень вы их надо использовать очень
точечно
смотри на накладывает ли такой подход к
рендеринга ограничения на отображение
или на конфигурацию отображения
изображений остановку поясню вопрос то
есть предположим что нам нужно отобрать
показать галерею в скроле да но мы не
знаем высоты картинки до сих пор пока не
загрузится вот какие то видишь эту
проблемы и возможные варианты решения
основная проблема в том что мы не знаем
размеров картинки надо знать и картинки
есть она получается но не получится
вообще это заставит работать или это
будет работать с проблемами на мой
взгляд не нужно пытаться заставлять это
работать потому что вообще отдавать
ссылку на картинку с размеров этой
картинке потому что во многих случаях
нам нужно резервировать какое-то место
для этой картинке у нас него там качков
поэтому
банально там прелоадер как нарисовать в
размер картинки не
другого мира поэтому просто всегда
давайте вместе со ссылкой на картинку
ещё и я размеры это несложно в принципе
и вы получаете хороший юзер экспириенс
насколько я понял основная мысль этого
доклада заключается в том что есть ну по
факту такая проблема есть wehbe
и есть два способа условного решения
первый способ это через откладывания
проблемы то есть мы там на пользу этот
тренд dream еще попозже попозже и второй
способ
когда мы не пытаемся увеличить
количество дом но туда идем именно в
логику вычислений и все операции с этим
связаны то есть получается что как бы
если мы пытаемся просто медленнее
добавлять элементов в dom дерева но как
бы это просто в руки раунда временно
которые на самом деле проблему не решает
ну это я перечислил 2 способ оптимизации
не но я будет виртуально 130
фундаментально на мой взгляд если можно
что-то не делать и пользователь не
заметил что вы это не сделали то лучше
так оделась
каунас доклад время доклада подходит
концу если же в чатике ссылочка на зон
хорошо продолжаем еще один вопрос как
быть с универсальным scroll им то есть
разные пользователи всяких мобильных
устройств привыкли к тому что дается ты
уж сильно там не знаю почему scroll у
тебя есть разная скорость этого
скалирования и хочется узнать у тебя не
мере не имею не мерил ли ты
производительность на мобильных
устройствах и действительно ли так
плавно работает то есть может ли
работать инерциальные scroll вместе с
виртуальным получается рендерингом
списков
да безусловно может и более того когда и
вот я экспериментировал у меня на
мобилках браузерная оптимизация оно
включалось всегда the browser всегда
выносил это на отдельный слой и
соответственно плавно не миру а вот на
десктопе как раз необходимо вот это вот
ручная вы нас в отдельный слой иначе
браузер пытается сэкономить на слоях
что свои они тоже не бесплатны и он
старается поменьше слоев выделять но из
за этого получается скал начинает тупить
из-за того что мы постоянно меняем дом
понял тебя нашего вопроса слушателей что
по поводу стики позиции позиционирования
то есть можно ли это когда применить в
рамках виртуального ского
да там собственно в дымке вы можете
посмотреть в дымке kettle оба там как
раскрывается стеки и там все работает и
местный момент что когда вы ищете идет
фокусировка на элемент этот элемент
наказывается самом верху и
паскаль кости кита же самом верху они
накладываются друг на друга браузер от
не учитывает
вот поэтому мне пришлось сделать такой
полупрозрачный чтобы пользователю хотя
бы было понятно что один элемент
там находится вот можно было бы
фокусировать так чтобы элемент находился
в середине но тут уже на как раз
появляются проблемы с виртуализацией
потому что мы сверху начинаем добавлять
или какой-то контент яд контроль можно
казаться больше
и соответственно
наш элемент уедет за видим область и
такой тыкай следующий ничего не видит в
общем такие компромисс
дим смотри на сколько я понимаю вот
минимальная работа виртуального scroll
она так или иначе но загружает процессор
до но на какую-то величину условную ты
показывал в демках вот может ты знаешь
вот где та грань когда нам имеет смысл
действительно уже переходить к
виртуальному скролла где мы можем
воспользоваться стандартным scroll am
браузера да ну потому что условно там на
размерах там да там 2000 дом элементов
то наверно там особо нечего тормозить не
будет может быть примерил смотрел то
есть когда браузер scroll нативный да по
производительности он еще выигрывает
виртуальный scroll
браузерные scroll он всегда выигрывает
виртуально браузер это дело ясное .
они играют в лол песка
да виртуальный выигрывают в случае когда
у нас действительно много контента
вот что такое много
он за все войско что ситуация
вот я показывал там пример с абрам там
всего 170 комментариев
и мы можем их показать за секунду а
можем показывать
сами решайте насколько
[музыка]
насколько вы готовы сделать так что
пользователь ждали
ну там проблема в том что
создатели хабра например они же не знают
сколько будет конкретно контента от
конкретно под каждой статьей
вот то есть по данной статьи там два
комментария под другой 2000
когда не знаешь сколько будет контента
тогда лучше заблаговременно меняясь
какую-то актуализацию пользоваться
понял тебя смотри вот если мы получается
начинаем вручную контролировать
количество дом элементов то следующие
проблемы которые у нас возникнет при
условном большом количестве данных да
это потребление памяти и может быть ты
узнал или там сталкивался с техниками
того когда нам нужно выгружать данные
там из памяти условно говоря то есть
текущие примеры берем кидание основаны
на том что у нас уже есть какие-то
комментарии которые но загружены в
память на условный там 300 штук а мы их
показываем
а если вдруг это что-то там около
биржевое там какие-то солодки и так
далее так далее нам надо показывать вам
стрим этих комментариев когда ли так
далее как это все сделать учетом того
что там надо если мы не будем ничего из
памяти выгружать вам просто
упадем браузер ну что ж ребят я вас
прерву на секундочку
1 этот вопрос уже ответ будет в
дискуссионной зоне до под нашим стрима
вы можете найти ссылочку на
дискуссионную зону на дискуссионную зону
в зуме александр дмитрий большое спасибо
вам за доклад за отличные вопросы это
было круто ребят поблагодарите парней в
чатике с маленьком что было все классно
там но может кому-то не понравился может
сказать что они классно но по мне так
доклад вышел отличный еще раз вам
большое спасибо за доклад
надеюсь увидеть вас на нашей платформе
там сегодня вечером может быть завтра и
пообщаться уже виртуальном пространстве
с вами хорошей вам дискуссии ребят
